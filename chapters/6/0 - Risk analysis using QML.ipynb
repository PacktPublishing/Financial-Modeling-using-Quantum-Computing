{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit risk analysis\n",
    "\n",
    "Our first approach to credit risk analysis will require some data to be used. This data is related to a set of households and their finantial status based on different factors (borough, max debt acquired by the household for a period of time, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>borough_county</th>\n",
       "      <th>primary_sector</th>\n",
       "      <th>company_type</th>\n",
       "      <th>annual_turnover</th>\n",
       "      <th>number_of_employees</th>\n",
       "      <th>turnover_bands</th>\n",
       "      <th>factoring_type</th>\n",
       "      <th>factoring_provider</th>\n",
       "      <th>...</th>\n",
       "      <th>turnover_wave12</th>\n",
       "      <th>turnover_wave13</th>\n",
       "      <th>turnover_wave14</th>\n",
       "      <th>turnover_vs_operating_cost_wave10</th>\n",
       "      <th>turnover_vs_operating_cost_wave11</th>\n",
       "      <th>turnover_vs_operating_cost_wave12</th>\n",
       "      <th>turnover_vs_operating_cost_wave13</th>\n",
       "      <th>turnover_vs_operating_cost_wave14</th>\n",
       "      <th>value_of_covid_based_loans_taken_out</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>858.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9205</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>-0.0330</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.2453</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>537.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9205</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>-0.0330</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>-0.2906</td>\n",
       "      <td>-0.8283</td>\n",
       "      <td>-0.3079</td>\n",
       "      <td>1.7716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-68.000000</td>\n",
       "      <td>26945.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>-0.0202</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.2453</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>447.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>-0.6217</td>\n",
       "      <td>-0.0330</td>\n",
       "      <td>-0.3414</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.2453</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32855.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9205</td>\n",
       "      <td>-0.6217</td>\n",
       "      <td>-0.0330</td>\n",
       "      <td>-0.3414</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>-0.8283</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>26217.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9205</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>-0.0330</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.2453</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>...</td>\n",
       "      <td>-66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>172.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.7430</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>-0.0202</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.2453</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>528.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>-0.0330</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.2453</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-77.000000</td>\n",
       "      <td>-44.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>326.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.7430</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>-0.0330</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.2453</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>344.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9205</td>\n",
       "      <td>-0.1203</td>\n",
       "      <td>-0.0330</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>-0.2906</td>\n",
       "      <td>-0.8283</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.879253</td>\n",
       "      <td>-5.821141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.011241</td>\n",
       "      <td>-4.644068</td>\n",
       "      <td>-4.528014</td>\n",
       "      <td>-2.68406</td>\n",
       "      <td>-3.590444</td>\n",
       "      <td>13669.49174</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  target  borough_county  primary_sector  company_type  \\\n",
       "0       858.0     0.0          2.9205          0.4856       -0.0330   \n",
       "1       537.0     0.0          2.9205          0.0106       -0.0330   \n",
       "2       302.0     0.0         -0.0118          0.4856       -0.0202   \n",
       "3       447.0     0.0         -0.0118         -0.6217       -0.0330   \n",
       "4       867.0     0.0          2.9205         -0.6217       -0.0330   \n",
       "5       305.0     0.0          2.9205          0.0106       -0.0330   \n",
       "6       172.0     1.0         -0.7430          0.0913       -0.0202   \n",
       "7       528.0     0.0         -0.0118          0.4856       -0.0330   \n",
       "8       326.0     1.0         -0.7430          0.4856       -0.0330   \n",
       "9       344.0     0.0          2.9205         -0.1203       -0.0330   \n",
       "\n",
       "   annual_turnover  number_of_employees  turnover_bands  factoring_type  \\\n",
       "0           0.0451               0.1019          0.2453          0.0226   \n",
       "1           0.0451              -0.2906         -0.8283         -0.3079   \n",
       "2           0.0451               0.1019          0.2453          0.0226   \n",
       "3          -0.3414               0.1019          0.2453          0.0226   \n",
       "4          -0.3414               0.1019         -0.8283          0.0226   \n",
       "5           0.0451               0.1019          0.2453          0.0226   \n",
       "6           0.0451               0.1019          0.2453          0.0226   \n",
       "7           0.0451               0.1019          0.2453          0.0226   \n",
       "8           0.0451               0.1019          0.2453          0.0226   \n",
       "9           0.0451              -0.2906         -0.8283          0.0226   \n",
       "\n",
       "   factoring_provider  ...  turnover_wave12  turnover_wave13  turnover_wave14  \\\n",
       "0              0.0226  ...        -8.000000         0.000000              0.0   \n",
       "1              1.7716  ...         0.000000         0.000000             -9.0   \n",
       "2              0.0226  ...       -74.000000         0.000000              0.0   \n",
       "3              0.0226  ...         0.000000        30.000000              0.0   \n",
       "4              0.0226  ...        11.000000         0.000000             -9.0   \n",
       "5              0.0226  ...       -66.000000         0.000000            -10.0   \n",
       "6              0.0226  ...       -10.000000        -9.000000             -9.0   \n",
       "7              0.0226  ...         0.000000         0.000000             13.0   \n",
       "8              0.0226  ...         0.000000         0.000000             12.0   \n",
       "9              0.0226  ...        -5.879253        -5.821141              0.0   \n",
       "\n",
       "   turnover_vs_operating_cost_wave10  turnover_vs_operating_cost_wave11  \\\n",
       "0                          15.000000                           0.000000   \n",
       "1                           0.000000                           0.000000   \n",
       "2                           5.000000                          -9.000000   \n",
       "3                          34.000000                           0.000000   \n",
       "4                           0.000000                           0.000000   \n",
       "5                           0.000000                         -80.000000   \n",
       "6                           0.000000                           0.000000   \n",
       "7                          41.000000                         -77.000000   \n",
       "8                          11.000000                           0.000000   \n",
       "9                           3.011241                          -4.644068   \n",
       "\n",
       "   turnover_vs_operating_cost_wave12  turnover_vs_operating_cost_wave13  \\\n",
       "0                         -12.000000                            0.00000   \n",
       "1                          15.000000                            0.00000   \n",
       "2                          -9.000000                            0.00000   \n",
       "3                           9.000000                            0.00000   \n",
       "4                           0.000000                            0.00000   \n",
       "5                         -10.000000                            0.00000   \n",
       "6                           0.000000                            0.00000   \n",
       "7                         -44.000000                            0.00000   \n",
       "8                           0.000000                            0.00000   \n",
       "9                          -4.528014                           -2.68406   \n",
       "\n",
       "   turnover_vs_operating_cost_wave14  value_of_covid_based_loans_taken_out  \\\n",
       "0                           7.000000                               0.00000   \n",
       "1                         -68.000000                           26945.00000   \n",
       "2                           0.000000                               0.00000   \n",
       "3                           0.000000                           32855.00000   \n",
       "4                          -7.000000                           26217.00000   \n",
       "5                           6.000000                               0.00000   \n",
       "6                           0.000000                               0.00000   \n",
       "7                           0.000000                               0.00000   \n",
       "8                          10.000000                               0.00000   \n",
       "9                          -3.590444                           13669.49174   \n",
       "\n",
       "   train  \n",
       "0    1.0  \n",
       "1    1.0  \n",
       "2    1.0  \n",
       "3    1.0  \n",
       "4    1.0  \n",
       "5    1.0  \n",
       "6    1.0  \n",
       "7    1.0  \n",
       "8    1.0  \n",
       "9    1.0  \n",
       "\n",
       "[10 rows x 167 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data loading from a CSV file\n",
    "fulldata = pd.read_csv('../../data/nayaone_synthetic_data.csv')\n",
    "\n",
    "# Transforming data to float\n",
    "data = fulldata.astype(float)\n",
    "data.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in any other Supervised Machine Learning case we will need to split the data into different chunks. First, splitting the data that is considered a feature (and will be used to assess the risk analysis) and the data that is considerd Label. Also, we will split the data into 70% used for training and 30% to establish how good our algorithm works with previously not seen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data for training and testing\n",
    "data_train = data.groupby([data.index,'train']).filter(lambda x: x['train'] == 1.).reset_index()\n",
    "data_test = data.groupby([data.index,'train']).filter(lambda x: x['train'] == 0.).reset_index()\n",
    "# Separate X and y considering dropping not useful columns\n",
    "X_train = data_train.drop(['target', 'Unnamed: 0', 'train'] ,axis=\"columns\")\n",
    "y_train = data_train['target']\n",
    "X_test = data_test.drop(['target', 'Unnamed: 0', 'train'] ,axis=\"columns\")\n",
    "y_test = data_test['target']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should always check that our dataset is balanced enough to avoid any bias on the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    70.422535\n",
       "1.0    29.577465\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the balance of the target variable in train\n",
    "y_train.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    70.545455\n",
       "1.0    29.454545\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the balance of the target variable in test\n",
    "y_test.value_counts(normalize=True)*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common that due to resource limitation becomes difficult to encode all available data into a QML algorithm. But it is also true that real-case data often comes with quite some noise that could affect our model so it is a good choice to play with dimensionality reduction techniques in order to compress all the information in a minimal subset of features and thus, avoid always present noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard split by half on the dataframe for the LDA dimensionality reduction\n",
    "\n",
    "# Train split\n",
    "features_a = X_train.iloc[:,:83]\n",
    "features_b = X_train.iloc[:,83:]\n",
    "\n",
    "# Test split\n",
    "features_a_test = X_test.iloc[:,:83]\n",
    "features_b_test = X_test.iloc[:,83:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# LDA fit with the separated groups\n",
    "lda1 = LDA(n_components=1, solver='svd').fit(features_a, y_train)\n",
    "lda2 = LDA(n_components=1, solver='svd').fit(features_b, y_train)\n",
    "\n",
    "# LDA train transformation\n",
    "features_lda_1 = lda1.transform(features_a)\n",
    "features_lda_2 = lda2.transform(features_b)\n",
    "\n",
    "# LDA test transformation (using train fit)\n",
    "features_lda_1_test = lda1.transform(features_a_test)\n",
    "features_lda_2_test = lda2.transform(features_b_test)\n",
    "\n",
    "# Arrays to dataframe for join in a single dataframe\n",
    "features_lda_1 = pd.DataFrame(features_lda_1)\n",
    "features_lda_2 = pd.DataFrame(features_lda_2)\n",
    "features_lda_1_test = pd.DataFrame(features_lda_1_test)\n",
    "features_lda_2_test = pd.DataFrame(features_lda_2_test)\n",
    "\n",
    "# Join of dataframes\n",
    "x_train_lda = pd.concat([features_lda_1, features_lda_2], axis=1)\n",
    "x_test_lda = pd.concat([features_lda_1_test, features_lda_2_test], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another factor that is common is the scale disparity. It is important that we make our models agnostic to the scale and able to focus on the information encoded into our features. It is also convenient when dealing with Neural Networks, as normalization always helps convergence.\n",
    "\n",
    "In this case we will replicate the information to different dataframes, acommodated to the target techniques we would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "\n",
    "## QSVC\n",
    "minmax_scaler = MinMaxScaler().fit(x_train_lda)\n",
    "X_train_qsvc = minmax_scaler.transform(x_train_lda)\n",
    "X_test_qsvc = minmax_scaler.transform(x_test_lda)\n",
    "\n",
    "## SVC\n",
    "strd_scaler = StandardScaler().fit(x_train_lda)\n",
    "X_train_svc = strd_scaler.transform(x_train_lda)\n",
    "X_test_svc = strd_scaler.transform(x_test_lda)\n",
    "\n",
    "## VQC\n",
    "strd_scaler = StandardScaler().fit(x_train_lda)\n",
    "X_train_vqc = strd_scaler.transform(x_train_lda)\n",
    "X_test_vqc = strd_scaler.transform(x_test_lda)\n",
    "y_train_vqc = pd.DataFrame(y_train)\n",
    "y_test_vqc = pd.DataFrame(y_test)\n",
    "\n",
    "## Quantum Neural Network\n",
    "minmax_scaler = MinMaxScaler().fit(x_train_lda)\n",
    "X_train_nn = minmax_scaler.transform(x_train_lda)\n",
    "X_test_nn = minmax_scaler.transform(x_test_lda)\n",
    "y_train_nn = y_train.to_numpy()\n",
    "y_test_nn = y_test.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Following lines will present some of the most common models used in classical ML and their quantum counterpart. We will register some common parameters so that they can be used by all following techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.utils import algorithm_globals\n",
    "\n",
    "# Features\n",
    "features_dim = len(x_test_lda.columns)\n",
    "\n",
    "# number of qubits is equal to the number of features \n",
    "num_qubits = features_dim\n",
    "\n",
    "# regularization parameter\n",
    "C = 1000\n",
    "\n",
    "# regularization parameter\n",
    "maxiter = 50\n",
    "\n",
    "# Random seed\n",
    "algorithm_globals.random_seed = 12345\n",
    "\n",
    "# Batch\n",
    "batch = 40\n",
    "\n",
    "# Shots\n",
    "shots = 1024\n",
    "\n",
    "# Features\n",
    "features_dim = num_qubits\n",
    "\n",
    "# Parameters for quantum implementations\n",
    "num_params = features_dim\n",
    "num_features = features_dim\n",
    "num_inputs = features_dim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC and QSVC\n",
    "\n",
    "Support Vector Classifiers arepretty well known techniques enabling the separability of data in high dimensional spaces for classiciation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC classification test score: 0.7927272727272727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "# Instantiate the SVC\n",
    "svc = SVC()\n",
    "\n",
    "# Training\n",
    "svc.fit(X_train_svc,y_train)\n",
    "\n",
    "# Testing\n",
    "svc_score = svc.score(X_test_svc, y_test)\n",
    "print(f\"SVC classification test score: {svc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85       194\n",
      "         1.0       0.65      0.65      0.65        81\n",
      "\n",
      "    accuracy                           0.79       275\n",
      "   macro avg       0.75      0.75      0.75       275\n",
      "weighted avg       0.79      0.79      0.79       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Classification report of SVC\n",
    "expected_y_svc  = y_test\n",
    "predicted_y_svc = svc.predict(X_test_svc) \n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification report: \\n\", metrics.classification_report(expected_y_svc, predicted_y_svc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classical counterpart of SVC takes advantage of the quantum embedding to improve the separability between the samples. For this a Quantum circuit known as a FeatureMap is used to map out classical observations to a quantum state that afterwards gets measures. By using this measured states instead of the original data we aim to improve the separability between our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.providers.aer import AerSimulator\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "\n",
    "# Defining backend and feature map to be used\n",
    "backend = QuantumInstance(\n",
    "     AerSimulator(method='statevector'),\n",
    "    seed_simulator=algorithm_globals.random_seed,\n",
    "    seed_transpiler=algorithm_globals.random_seed,\n",
    ")\n",
    "\n",
    "# ZZ feature map\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_qubits, reps=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how this Feature Maps is composed by parameterized actions where our data will be introduced to create data-specific quantum states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1875.91x200.667 with 1 Axes>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature map circuit print\n",
    "feature_map.decompose().draw(output = \"mpl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The our Quantum SVC will use this feature map to find the best way in which to split our newly encoded quantum data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QSVC classification test score: 0.7927272727272727\n"
     ]
    }
   ],
   "source": [
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "\n",
    "# Defining quantum kernel and qsvc\n",
    "qkernel = QuantumKernel(feature_map=feature_map, quantum_instance=backend)\n",
    "qsvc = QSVC(quantum_kernel=qkernel, C=C)\n",
    "\n",
    "# Training\n",
    "qsvc.fit(X_train_qsvc,y_train)\n",
    "\n",
    "# Testing\n",
    "qsvc_score = qsvc.score(X_test_qsvc, y_test)\n",
    "print(f\"QSVC classification test score: {qsvc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.82      0.85       194\n",
      "         1.0       0.63      0.73      0.67        81\n",
      "\n",
      "    accuracy                           0.79       275\n",
      "   macro avg       0.75      0.77      0.76       275\n",
      "weighted avg       0.80      0.79      0.80       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report of QSVC\n",
    "expected_y_qsvc  = y_test\n",
    "predicted_y_qsvc = qsvc.predict(X_test_qsvc) \n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification report: \\n\", metrics.classification_report(expected_y_qsvc, predicted_y_qsvc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there is some improvement over the previous example. At least some samples where better classified thanks to a simple encoding if you look at the classificatino report (class 1.0)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "Neural networks are known to be very versatile models capable of approximation almost any relationship (between features and labels). We will fit a simple approach composed by three layers of 60, 40 and 20 ReLU units and a final sigmoid action on a single unit. Adam will be the optimization approach and binary crossentropy the cost function associated to our binary classification task.\n",
    "\n",
    "Gradient based training algorithms like Adam will require gradient calculations but that is when frameworks such as TensorFlow and Keras will become handy (make sure you have them installed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General definitions\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 3s 41ms/step - loss: 0.6807 - accuracy: 0.6980 - val_loss: 0.6653 - val_accuracy: 0.7055\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6451 - accuracy: 0.7074 - val_loss: 0.6220 - val_accuracy: 0.7091\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.5894 - accuracy: 0.7324 - val_loss: 0.5695 - val_accuracy: 0.7309\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5106 - accuracy: 0.8059 - val_loss: 0.5068 - val_accuracy: 0.8255\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3985 - accuracy: 0.9092 - val_loss: 0.4281 - val_accuracy: 0.8509\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2785 - accuracy: 0.9468 - val_loss: 0.3722 - val_accuracy: 0.8364\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1919 - accuracy: 0.9624 - val_loss: 0.3497 - val_accuracy: 0.8255\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1472 - accuracy: 0.9593 - val_loss: 0.3398 - val_accuracy: 0.8291\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1238 - accuracy: 0.9609 - val_loss: 0.3556 - val_accuracy: 0.8255\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1163 - accuracy: 0.9640 - val_loss: 0.3678 - val_accuracy: 0.8255\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1162 - accuracy: 0.9624 - val_loss: 0.3935 - val_accuracy: 0.8182\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1076 - accuracy: 0.9609 - val_loss: 0.3927 - val_accuracy: 0.8182\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1055 - accuracy: 0.9640 - val_loss: 0.3959 - val_accuracy: 0.8291\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1023 - accuracy: 0.9624 - val_loss: 0.4217 - val_accuracy: 0.8182\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1053 - accuracy: 0.9593 - val_loss: 0.4318 - val_accuracy: 0.8145\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1113 - accuracy: 0.9640 - val_loss: 0.4219 - val_accuracy: 0.8182\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1072 - accuracy: 0.9624 - val_loss: 0.4245 - val_accuracy: 0.8182\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1078 - accuracy: 0.9593 - val_loss: 0.4502 - val_accuracy: 0.8109\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1030 - accuracy: 0.9624 - val_loss: 0.4405 - val_accuracy: 0.8145\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1016 - accuracy: 0.9593 - val_loss: 0.4553 - val_accuracy: 0.8145\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1019 - accuracy: 0.9656 - val_loss: 0.4443 - val_accuracy: 0.8218\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1006 - accuracy: 0.9624 - val_loss: 0.4502 - val_accuracy: 0.8182\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1014 - accuracy: 0.9656 - val_loss: 0.4500 - val_accuracy: 0.8109\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1020 - accuracy: 0.9609 - val_loss: 0.4612 - val_accuracy: 0.8109\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0997 - accuracy: 0.9624 - val_loss: 0.4597 - val_accuracy: 0.8145\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1002 - accuracy: 0.9624 - val_loss: 0.4588 - val_accuracy: 0.8073\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1065 - accuracy: 0.9593 - val_loss: 0.4603 - val_accuracy: 0.8109\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1010 - accuracy: 0.9624 - val_loss: 0.4681 - val_accuracy: 0.8182\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1024 - accuracy: 0.9640 - val_loss: 0.4821 - val_accuracy: 0.8109\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1048 - accuracy: 0.9640 - val_loss: 0.4665 - val_accuracy: 0.8000\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1069 - accuracy: 0.9624 - val_loss: 0.4691 - val_accuracy: 0.8036\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1016 - accuracy: 0.9593 - val_loss: 0.4709 - val_accuracy: 0.8036\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0984 - accuracy: 0.9609 - val_loss: 0.4693 - val_accuracy: 0.8036\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0994 - accuracy: 0.9609 - val_loss: 0.4812 - val_accuracy: 0.8073\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1009 - accuracy: 0.9624 - val_loss: 0.4827 - val_accuracy: 0.8073\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1021 - accuracy: 0.9656 - val_loss: 0.4716 - val_accuracy: 0.8000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0993 - accuracy: 0.9593 - val_loss: 0.4903 - val_accuracy: 0.8073\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0990 - accuracy: 0.9640 - val_loss: 0.4762 - val_accuracy: 0.7964\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1021 - accuracy: 0.9624 - val_loss: 0.4826 - val_accuracy: 0.8073\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1040 - accuracy: 0.9624 - val_loss: 0.4871 - val_accuracy: 0.8036\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1034 - accuracy: 0.9609 - val_loss: 0.4801 - val_accuracy: 0.8036\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0980 - accuracy: 0.9624 - val_loss: 0.4829 - val_accuracy: 0.8073\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0989 - accuracy: 0.9624 - val_loss: 0.4897 - val_accuracy: 0.8073\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1076 - accuracy: 0.9624 - val_loss: 0.4818 - val_accuracy: 0.7927\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1006 - accuracy: 0.9656 - val_loss: 0.4849 - val_accuracy: 0.8036\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1045 - accuracy: 0.9624 - val_loss: 0.4970 - val_accuracy: 0.8109\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1018 - accuracy: 0.9624 - val_loss: 0.4829 - val_accuracy: 0.8036\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0985 - accuracy: 0.9624 - val_loss: 0.4976 - val_accuracy: 0.8073\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1025 - accuracy: 0.9640 - val_loss: 0.4804 - val_accuracy: 0.7891\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1049 - accuracy: 0.9671 - val_loss: 0.4859 - val_accuracy: 0.8036\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Fit the model with specific layers and activations\n",
    "model = Sequential()\n",
    "model.add(Dense(60, input_dim=X_train_nn.shape[1], activation='relu', kernel_initializer='normal'))\n",
    "model.add(Dense(40,activation='relu'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# Model compiled\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train_nn, y_train, batch_size=batch, \n",
    "                 epochs=50, validation_data = (X_test_nn, y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.8036\n",
      "NN test aacuracy score: 80.36%\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "nn_score = model.evaluate(X_test_nn, y_test)\n",
    "print(\"NN test accuracy score: %.2f%%\" % (nn_score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.87      0.86       194\n",
      "         1.0       0.67      0.65      0.66        81\n",
      "\n",
      "    accuracy                           0.80       275\n",
      "   macro avg       0.76      0.76      0.76       275\n",
      "weighted avg       0.80      0.80      0.80       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report of NN\n",
    "expected_y_nn  = y_test\n",
    "predicted_y_nn = (model.predict(X_test_nn) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification report: \\n\", metrics.classification_report(expected_y_nn, predicted_y_nn))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. Similar to our original SVC approach. Let's try now with Qiskit enabled Quantum Neural Networks. Two main pieces will compose our quantum NN:\n",
    "\n",
    "* Feature map: where the classical data gets encoded as quantum states\n",
    "* Ansatz or PQC: A parameterized set of gates that act as layers in our network\n",
    "\n",
    "Given the measurements we can produce in Qiskit the simpler case is the binary classification, even though by stacking several binary classifiers a multi-label classifier can also be composed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 621.739x200.667 with 1 Axes>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
    "\n",
    "# Declare the feature map\n",
    "feature_map = ZZFeatureMap(num_inputs)\n",
    "\n",
    "# Declare the ansatz\n",
    "ansatz = RealAmplitudes(num_inputs, reps=2) \n",
    "\n",
    "# Construct the quantum circuit\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "qc.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.providers.aer import Aer\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN\n",
    "from qiskit.algorithms.optimizers import L_BFGS_B\n",
    "\n",
    "# Maps bitstrings to 0 or 1\n",
    "def parity(x):\n",
    "    return \"{:b}\".format(x).count(\"1\") % 2\n",
    "\n",
    "# Defining quantum instance\n",
    "quantum_instance = QuantumInstance(Aer.get_backend(\"aer_simulator\"), shots=shots)\n",
    "\n",
    "# Declare the QNN circuit\n",
    "circuit_qnn = CircuitQNN(\n",
    "    circuit=qc,\n",
    "    input_params=feature_map.parameters,\n",
    "    weight_params=ansatz.parameters,\n",
    "    interpret=parity,\n",
    "    output_shape=2,\n",
    "    quantum_instance=quantum_instance,\n",
    ")\n",
    "\n",
    "# Declare the classifier\n",
    "circuit_classifier = NeuralNetworkClassifier(\n",
    "            neural_network=circuit_qnn, optimizer= L_BFGS_B(maxiter=maxiter), loss='absolute_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qiskit_machine_learning.algorithms.classifiers.neural_network_classifier.NeuralNetworkClassifier at 0x7f17ae572790>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit_classifier.fit(X_train_nn,y_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.67      0.77       194\n",
      "         1.0       0.51      0.83      0.63        81\n",
      "\n",
      "    accuracy                           0.72       275\n",
      "   macro avg       0.71      0.75      0.70       275\n",
      "weighted avg       0.79      0.72      0.73       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = circuit_classifier.predict(X_test_nn)\n",
    "\n",
    "# print classification report and confusion matrix for the classifier\n",
    "print(\"Classification report: \\n\", metrics.classification_report(y_test_nn, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well we got to improve a little bit but lets try with some gradient training and a more generic approach. In this case, Pennylane will help us minimize the amount of implementation to be done for our Variational Quantum Classifier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Quantum Classifier\n",
    "\n",
    "We will check for a more generic approach thanks to Pennylane. As we already discussed in previous chapters, Pennylane allows for automatic differentiation similar to how tensorflow or pytorch work at classical level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PennyLane\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np # this is conflicting with regular numpy on first line\n",
    "from pennylane.templates.embeddings import AngleEmbedding\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "\n",
    "# Device\n",
    "dev = qml.device('default.qubit', wires = num_qubits)\n",
    "\n",
    "# Our generic candidate circuit\n",
    "def circuit(parameters, X_train_vqc):\n",
    "    for i in range(num_qubits):\n",
    "        qml.Hadamard(wires = i)\n",
    "    \n",
    "    # Angle embedding for classical embedding\n",
    "    AngleEmbedding(features = X_train_vqc, wires = range(num_qubits), rotation = 'Y')\n",
    "    \n",
    "    # This will be our PQC of choice\n",
    "    qml.StronglyEntanglingLayers(weights = parameters, wires = range(num_qubits))\n",
    "    \n",
    "    # And measuring on 0 qubit we will get if it corresponds to one or other label\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the device and our candidate circuit are set we just need to amrry the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QNode: Device + Circuit\n",
    "vqc = qml.QNode(circuit, dev, diff_method=\"backprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters definition\n",
    "num_layers = 5\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our circuit can be used as it sits..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.30397452, requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqc(weights_init, X_train_vqc[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But better if we train it like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VQC functions\n",
    "def variational_classifier(weights, bias, x):\n",
    "    return vqc(weights, x) + bias\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Iter:     1 | Cost: 0.6364835 | Accuracy: 0.7981221 \n",
      "New best\n",
      "Iter:     2 | Cost: 0.3122628 | Accuracy: 0.9358372 \n",
      "New best\n",
      "Iter:     3 | Cost: 0.2477873 | Accuracy: 0.9405321 \n",
      "Iter:     4 | Cost: 0.2545324 | Accuracy: 0.9389671 \n",
      "Iter:     5 | Cost: 0.2693816 | Accuracy: 0.9389671 \n",
      "New best\n",
      "Iter:     6 | Cost: 0.2902558 | Accuracy: 0.9452269 \n",
      "New best\n",
      "Iter:     7 | Cost: 0.2817261 | Accuracy: 0.9530516 \n",
      "New best\n",
      "Iter:     8 | Cost: 0.2631272 | Accuracy: 0.9577465 \n",
      "New best\n",
      "Iter:     9 | Cost: 0.2392357 | Accuracy: 0.9624413 \n",
      "Iter:    10 | Cost: 0.2215741 | Accuracy: 0.9624413 \n",
      "Iter:    11 | Cost: 0.2097524 | Accuracy: 0.9593114 \n",
      "Iter:    12 | Cost: 0.2076297 | Accuracy: 0.9593114 \n",
      "New best\n",
      "Iter:    13 | Cost: 0.1977010 | Accuracy: 0.9640063 \n",
      "Iter:    14 | Cost: 0.1966792 | Accuracy: 0.9593114 \n",
      "Iter:    15 | Cost: 0.1901099 | Accuracy: 0.9624413 \n",
      "Iter:    16 | Cost: 0.1872909 | Accuracy: 0.9577465 \n",
      "Iter:    17 | Cost: 0.1937690 | Accuracy: 0.9593114 \n",
      "Iter:    18 | Cost: 0.1941856 | Accuracy: 0.9593114 \n",
      "Iter:    19 | Cost: 0.1940818 | Accuracy: 0.9593114 \n",
      "Iter:    20 | Cost: 0.1933347 | Accuracy: 0.9608764 \n",
      "Iter:    21 | Cost: 0.1890536 | Accuracy: 0.9593114 \n",
      "Iter:    22 | Cost: 0.1852178 | Accuracy: 0.9577465 \n",
      "Iter:    23 | Cost: 0.1823091 | Accuracy: 0.9577465 \n",
      "Iter:    24 | Cost: 0.1802065 | Accuracy: 0.9561815 \n",
      "Iter:    25 | Cost: 0.1804786 | Accuracy: 0.9577465 \n",
      "Iter:    26 | Cost: 0.1820027 | Accuracy: 0.9593114 \n",
      "Iter:    27 | Cost: 0.1843989 | Accuracy: 0.9593114 \n",
      "Iter:    28 | Cost: 0.1872900 | Accuracy: 0.9561815 \n",
      "New best\n",
      "Iter:    29 | Cost: 0.1759054 | Accuracy: 0.9655712 \n",
      "Iter:    30 | Cost: 0.1665036 | Accuracy: 0.9608764 \n",
      "Iter:    31 | Cost: 0.1686598 | Accuracy: 0.9655712 \n",
      "Iter:    32 | Cost: 0.1828230 | Accuracy: 0.9561815 \n",
      "Iter:    33 | Cost: 0.1929093 | Accuracy: 0.9514867 \n",
      "Iter:    34 | Cost: 0.1902182 | Accuracy: 0.9514867 \n",
      "Iter:    35 | Cost: 0.1723779 | Accuracy: 0.9593114 \n",
      "Iter:    36 | Cost: 0.1646253 | Accuracy: 0.9624413 \n",
      "Iter:    37 | Cost: 0.1766887 | Accuracy: 0.9640063 \n",
      "New best\n",
      "Iter:    38 | Cost: 0.1869206 | Accuracy: 0.9671362 \n",
      "Iter:    39 | Cost: 0.1771321 | Accuracy: 0.9640063 \n",
      "Iter:    40 | Cost: 0.1700432 | Accuracy: 0.9640063 \n",
      "Iter:    41 | Cost: 0.1624051 | Accuracy: 0.9577465 \n",
      "Iter:    42 | Cost: 0.1643590 | Accuracy: 0.9577465 \n",
      "Iter:    43 | Cost: 0.1712398 | Accuracy: 0.9577465 \n",
      "Iter:    44 | Cost: 0.1779437 | Accuracy: 0.9577465 \n",
      "Iter:    45 | Cost: 0.1748338 | Accuracy: 0.9593114 \n",
      "Iter:    46 | Cost: 0.1651646 | Accuracy: 0.9593114 \n",
      "Iter:    47 | Cost: 0.1575564 | Accuracy: 0.9593114 \n",
      "Iter:    48 | Cost: 0.1536776 | Accuracy: 0.9577465 \n",
      "Iter:    49 | Cost: 0.1532939 | Accuracy: 0.9608764 \n",
      "Iter:    50 | Cost: 0.1554685 | Accuracy: 0.9608764 \n"
     ]
    }
   ],
   "source": [
    "# Optimizer declaration and batch parameter\n",
    "opt = AdamOptimizer(stepsize=0.1, beta1=0.9, beta2=0.99, eps=1e-08)\n",
    "batch_size = batch\n",
    "\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "wbest = 0\n",
    "bbest = 0\n",
    "abest = 0\n",
    "\n",
    "# X and y definition with shift label from [[0, 1] to [-1, 1]\n",
    "Y = np.array(y_train_vqc.values[:,0] * 2 - np.ones(len(y_train_vqc.values[:,0])), requires_grad = False)\n",
    "X = np.array(X_train_vqc, requires_grad=False)\n",
    "\n",
    "for it in range(50):\n",
    "\n",
    "    # Weights update by each optimizer step\n",
    "\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Accuracy computation\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "\n",
    "    acc = accuracy(Y, predictions)\n",
    "    \n",
    "    if acc > abest:\n",
    "        wbest = weights\n",
    "        bbest = bias\n",
    "        abest = acc\n",
    "        print('New best')\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VQC test accuracy score: 79.0%\n"
     ]
    }
   ],
   "source": [
    "# X_test and y_test transformation to be analyzed\n",
    "Yte = np.array(y_test_vqc.values[:,0] * 2 - np.ones(len(y_test_vqc.values[:,0])), requires_grad = False)\n",
    "Xte = np.array(normalize(X_test_vqc), requires_grad=False)\n",
    "\n",
    "# Testing\n",
    "predictions = [np.sign(variational_classifier(wbest, bbest, x)) for x in Xte]\n",
    "accuracy_vqc = accuracy(Yte, predictions)\n",
    "\n",
    "print(f'VQC test accuracy score: {np.round(accuracy_vqc, 2) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.89      0.79      0.84       194\n",
      "         1.0       0.61      0.77      0.68        81\n",
      "\n",
      "    accuracy                           0.79       275\n",
      "   macro avg       0.75      0.78      0.76       275\n",
      "weighted avg       0.81      0.79      0.79       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report of VQC\n",
    "expected_y_vqc  = Yte\n",
    "predicted_y_vqc = predictions \n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification report: \\n\", metrics.classification_report(expected_y_vqc, predicted_y_vqc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "103bead1b3505221cf3c93684cd5f873d89729dddf7b8625d3d8bb582bc8ea06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
